# PhD XAI Prototype Plan

This repository tracks my PhD proof-of-concept (POC) for **Explainable AI (XAI) in Healthcare** using GitHub Issues, Milestones, and a Project Board.  

## Weekly Plan & Deliverables

### Week 0 (Aug 21–23): Prep
- **Action**: Finalise scope, data assumptions, risks.  
- **Coding**: Install Python, Jupyter, spaCy, scikit-learn.  
- **Deliverable**: `README.md`, `docs/env-check.png`.  

### Week 1 (Aug 25–30): Text Preprocessing & Initial NER
- Write a script to read sample notes.  
- Use **scispaCy** for sentence splitting, **Med7** for NER (medications).  
- Read 3–4 KDD XAI papers (focus on utility, not math).  
- **Deliverable**: `01_text_preproc_ner.ipynb`.  

### Week 2 (Sep 1–6): Feature Extraction & Baselines
- Convert entities → numerical features.  
- Train LogisticRegression + RandomForest.  
- Implement SHAP TabularExplainer.  
- **Deliverable**: `02_features_models_shap.ipynb`.  

### Week 3 (Sep 8–13): Explainability & Basic UI
- Apply LIME for local explanations.  
- Build a simple Streamlit app (or Jupyter narrative).  
- **Deliverable**: `03_xai_comparison.ipynb`, `streamlit_app.py`.  

### Week 4 (Sep 15–20): Clinical & GIRFT Alignment
- Add **negspaCy** for negation handling.  
- Refine feature extraction with relationships.  
- Align with GIRFT diagram principles.  
- **Deliverable**: `04_temporality_negation.ipynb`, `GIRFT_Alignment_Note.docx`.  

### Week 5 (Sep 22–27): Risk & Governance
- Simple bias checks.  
- Draft Model Card & Risk Register.  
- **Deliverable**: `Risk_Register.docx`, `Model_Card.docx`.  

### Week 6 (Sep 29–Oct 4): Demo Hardening
- Finalise app/demo.  
- Address feedback with micro-experiment (SHAP vs LIME).  
- **Deliverable**: Demo notebook + `Demo_Script.docx`.  

### Week 7 (Oct 6–11): Buffer & Polish
- Dry runs, bug fixes, final deck.  
- **Deliverable**: Final evidence pack.  

---

## Five ML Concepts in Scope
1. **Feature Leakage** → avoid using future info in features.  
2. **Calibration & Thresholds** → mapping model probability → action.  
3. **Class Imbalance** → rare positive outcomes need handling.  
4. **Global vs Local Explainability** → SHAP (global) vs LIME (local).  
5. **Robustness & Fairness** → ensure performance across variations.  

---

##  How AI Adds Value
- **Speed & Consistency**: Automated note processing.  
- **Traceability & Trust**: Transparent explanations for clinicians.  
- **Standardization (GIRFT-aligned)**: Reduce unwarranted variation in clinical decision-making.  

---

## Research Strategy
For each Research paper:  
- Problem addressed.  
- XAI method used.  
- How explanation was presented.  
- Limitations noted.  

---
